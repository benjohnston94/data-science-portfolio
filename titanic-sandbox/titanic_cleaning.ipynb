{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Types\n",
    "from pandas import DataFrame # for type hints\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps\n",
    "\n",
    "* Need to deal with missing values\n",
    "* Need to convert columns to dummy variables\n",
    "* Need to drop irrelevant columms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def drop_rows(df: DataFrame,\n",
    "#                cols: List[str] = [\"Embarked\"]):\n",
    "#     \"\"\"\n",
    "#     For specific columns with only a couple of null values, \n",
    "#     drop these values for ease\n",
    "#     \"\"\"\n",
    "#     for col in cols:\n",
    "#         df = df.loc[raw[col].notnull()].copy()\n",
    "    \n",
    "#     return df\n",
    "\n",
    "def impute_incomplete_cols(df: DataFrame,\n",
    "                           cols: List[str] = [\"Age\"],\n",
    "                           impute_method: str = \"median\") -> DataFrame:\n",
    "    \"\"\"\n",
    "    for a given set of columns, imput the value of the specified type\n",
    "    \"\"\"\n",
    "    for col in cols:\n",
    "        if impute_method == \"median\":\n",
    "            df[col].fillna(df[col].median(), inplace=True)\n",
    "        elif impute_method == \"mean\":\n",
    "            df[col].fillna(df[col].mean(), inplace=True)\n",
    "        elif impute_method == \"min\":\n",
    "            df[col].fillna(df[col].min(), inplace=True)\n",
    "        elif impute_method == \"max\":\n",
    "            df[col].fillna(df[col].max(), inplace=True)\n",
    "        else:\n",
    "            print(f\"Unknown impute method: {impute_method}\")\n",
    "            \n",
    "    return df\n",
    "\n",
    "def missing_to_boolean(df: DataFrame,\n",
    "                       cols: List[str] = [\"Cabin\"]) -> DataFrame:\n",
    "    \"\"\"\n",
    "    for columns with too many missing values we just assign\n",
    "    a value to specify if null or not\n",
    "    \"\"\"\n",
    "    for col in cols:\n",
    "        df[f\"{col}_value_present\"] = df[col].notnull()\n",
    "    \n",
    "    return df\n",
    "\n",
    "def convert_to_dummy(df: DataFrame,\n",
    "                     cols: List[str] = [\"Sex\", \"Embarked\"]) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Convert specified categorical columns to dummy variables\n",
    "    \"\"\"\n",
    "    for col in cols:\n",
    "        dummies = pd.get_dummies(df[col], drop_first=True)\n",
    "        df = df.join(dummies).copy()\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def drop_cols(df: DataFrame,\n",
    "              cols: List[str] = [\"PassengerId\", \"Name\", \"Sex\", \"Ticket\", \"Cabin\", \"Embarked\"]) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Put this at the end so can run pipeline without \n",
    "    functions but still remove unusable columns. \n",
    "    Includes all columns converted to dummy variables\n",
    "    \"\"\"\n",
    "    df.drop(cols, axis=1, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def drop_rows(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Drop all rows with nulls remaining.\n",
    "    Putting this at the end catches anything which had nulls to begin with and \n",
    "    will also drop any related columns that manipulated these rows (e.g. dummy variables)\n",
    "    \"\"\"\n",
    "    df.dropna()\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_clean_data(file_path: str = \"titanic_train.csv\") -> DataFrame:\n",
    "    \"\"\"\n",
    "    Reads in titanic file and cleans the data\n",
    "    \"\"\"\n",
    "    raw = pd.read_csv(file_path)\n",
    "\n",
    "    clean = (\n",
    "        raw             \n",
    "        .pipe(impute_incomplete_cols)\n",
    "        .pipe(missing_to_boolean)\n",
    "        .pipe(convert_to_dummy)\n",
    "        .pipe(drop_cols)\n",
    "        .pipe(drop_rows)\n",
    "    )\n",
    "\n",
    "    assert clean.isna().sum().sum() == 0, \"still null values\"\n",
    "    \n",
    "    return clean\n",
    "\n",
    "def pickle_clean_data(df: DataFrame,\n",
    "                      save_target: str = \"titanic_train_clean\"):\n",
    "    \"\"\"\n",
    "    Takes in a dataframe and pickles it\n",
    "    with the given name\n",
    "    \"\"\"\n",
    "    df.to_pickle(save_target)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    df = read_and_clean_data()\n",
    "    pickle_clean_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gcenv_jup36] *",
   "language": "python",
   "name": "conda-env-gcenv_jup36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
